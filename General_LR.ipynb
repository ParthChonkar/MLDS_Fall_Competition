{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Setting up data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MLDS_Competition.ipynb', 'training_dataset.csv', 'General_LR.ipynb', 'Decision Boundaries.ipynb', '.DS_Store', 'savedModel1.pt', 'try1.pt', 'test_dataset.csv', '.ipynb_checkpoints', 'FeatureDescriptions.csv', 'sample_submission.csv']\n",
      "135.53289883517826\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(\"../MLDS\"))\n",
    "\n",
    "#import and shuffle training data\n",
    "original_data = pd.read_csv(\"../MLDS/training_dataset.csv\").sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "\n",
    "#get rid of text columns \n",
    "data = original_data.drop(columns=[\"text\"])\n",
    "\n",
    "\n",
    "#set prose to 0 and poetry to 1 \n",
    "for x in range(0,469):\n",
    "    if(data.iloc[x,27]=='prose'):\n",
    "        data.iloc[x,27] = 0\n",
    "    else:\n",
    "        data.iloc[x,27] = 1\n",
    "\n",
    "\n",
    "print(original_data.iloc[:,0].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([350, 26])\n",
      "torch.Size([119, 26])\n"
     ]
    }
   ],
   "source": [
    "X_train = torch.tensor(data.iloc[0:350,1:27].values).float()\n",
    "X_val = torch.tensor(data.iloc[350:469,1:27].values)\n",
    "\n",
    "\n",
    "Y_train = torch.tensor(data.iloc[0:350,27].values)\n",
    "Y_train = Y_train.view(350,-1)\n",
    "Y_val = torch.tensor(data.iloc[351:469,27].values)\n",
    "Y_val = Y_val.view(118,-1) #PROBLEM!!!!!!!\n",
    "\n",
    "print(X_train.size())\n",
    "print(X_val.size())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Creating Models, Optimzers, Trainers, Cost Functions, etc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class simple_logreg(nn.Module):\n",
    "    \n",
    "    def __init__(self,inputs):\n",
    "        super(simple_logreg, self).__init__()\n",
    "        self.linear = nn.Linear(inputs,1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        return torch.sigmoid(self.linear(x))\n",
    "\n",
    "    \n",
    "model = simple_logreg(20)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.5, momentum = 0.5)\n",
    "\n",
    "cost = nn.BCELoss()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def batch_GD(epochs):\n",
    "    for e in range (epochs):\n",
    "        optimizer.zero_grad()\n",
    "        prediction = model(X_train.float()[:,0:20])\n",
    "        loss = cost(prediction,Y_train.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        #debugging\n",
    "        #print(\"Prediction: \", prediction[0:5])\n",
    "        #print(\"Answer: \", Y_train.float()[0:5])\n",
    "        #print(\"Grads of: \" , model.state_dict())\n",
    "        #for p in model.parameters():\n",
    "            #print(p.grad)\n",
    "        \n",
    "        print(\"Loss: \",loss)\n",
    "    \n",
    "def stochastic_GD(epochs):\n",
    "    for epoch in range(epochs):\n",
    "        totalCost = 0\n",
    "        for i in range(350):\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(X_train[i,0:20].float())\n",
    "            loss = cost(pred,Y_train[i].float())\n",
    "            totalCost+=loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "\n",
    "        if(epoch%500==0):\n",
    "            print(\"Cost: \", totalCost)\n",
    "            print(model.state_dict())\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noprintstochastic_GD(epochs):\n",
    "    for epoch in range(epochs):\n",
    "        totalCost = 0\n",
    "        for i in range(350):\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(X_train[i,0:20].float())\n",
    "            loss = cost(pred,Y_train[i].float())\n",
    "            totalCost+=loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1, momentum = 0.5)\n",
    "noprintstochastic_GD(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"../MLDS/try1.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1186, grad_fn=<BinaryCrossEntropyBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/envs/learningML/lib/python3.5/site-packages/torch/nn/functional.py:2016: UserWarning: Using a target size (torch.Size([118])) that is different to the input size (torch.Size([118, 1])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
     ]
    }
   ],
   "source": [
    "print(cost(model(X_val[1:,0:20].float()),Y_val.float()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0,\n",
      "        0, 1, 1, 1, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "print(Y_val[0:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "savedModel = simple_logreg(20)\n",
    "savedModel.load_state_dict(torch.load('savedModel1.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9745762711864406\n"
     ]
    }
   ],
   "source": [
    "numRight = 0\n",
    "total = 0\n",
    "newPred = savedModel(X_val[1:,0:20].float())\n",
    "for x in range(118):\n",
    "    if(newPred[x]>0.5):\n",
    "        newPred[x] = 1\n",
    "    else:\n",
    "        newPred[x] = 0\n",
    "#print(newPred)\n",
    "\n",
    "for x in range(118):\n",
    "    if (newPred[x].float()==Y_val[x].float()):\n",
    "        numRight = numRight + 1\n",
    "    total = total + 1\n",
    "\n",
    "print(\"Accuracy: \",  numRight/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#95% accuracy yay "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost:  tensor(28.9740, grad_fn=<AddBackward0>)\n",
      "Cost:  tensor(29.7459, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "def savedModelGD(epochs):\n",
    "    for epoch in range(epochs):\n",
    "        totalCost = 0\n",
    "        for i in range(350):\n",
    "            optimizer.zero_grad()\n",
    "            pred = savedModel(X_train[i,0:20].float())\n",
    "            loss = cost(pred,Y_train[i].float())\n",
    "            totalCost+=loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        if(epoch%500==0):\n",
    "            print(\"Cost: \", totalCost)\n",
    "\n",
    "optimizer = torch.optim.SGD(savedModel.parameters(), lr=1, momentum = 0.5)\n",
    "savedModelGD(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(savedModel.state_dict(), \"../MLDS/savedModel1.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo: Keep running the above method and taking cost of saved Model down. Parameters are working well but we haven't reached min yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
